{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313c23d0",
   "metadata": {},
   "source": [
    "# Transformer_PyTorch_From_Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665dd98f",
   "metadata": {},
   "source": [
    "### Test GPU compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aebcef79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "CUDA available: True\n",
      "Device: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6e8789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ce5a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch Main module - for tensor operations and deep learning - Essential for building transformer from scratch\n",
    "# because all operations (attention, matrix multiplication, layers) are built using PyTorch tensors\n",
    "import torch\n",
    "\n",
    "# This imports PyTorch’s neural network module. It contains building blocks such as: nn.Linear, nn.Embedding, nn.LayerNorm\n",
    "# nn.Dropout, nn.Modul, Transformers heavily rely on these layers\n",
    "import torch.nn as nn\n",
    "\n",
    "# Imports optimizers like: optim.Adam, optim.SGD, optim.AdamW (often used for Transformers).\n",
    "# Required for updating model weights during training using backpropagation.\n",
    "import torch.optim as optim\n",
    "\n",
    "# Used for handling compressed files (.gz)\n",
    "import gzip\n",
    "\n",
    "# Provides functions to work with time. Used to:\n",
    "# measure training speed, compute time per epoch, log ETA/output intervals\n",
    "# Example: start = time.time(), elapsed = time.time() - start.\n",
    "import time\n",
    "\n",
    "# Gives access to mathematical functions such as: math.sqrt, math.log, math.pi\n",
    "import math\n",
    "\n",
    "# import spacy library. It is for text-processing library. Often used for: tokenization, sentence splitting, cleaning text\n",
    "import spacy\n",
    "\n",
    "# Helps build custom datasets and efficiently load batches\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# importing pad_seq for maintain the seq len as it is crucial for NLP\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# visualize the progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06492993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the language models\n",
    "# 1. de - German language\n",
    "# 2. en - Eng Language\n",
    "# sm - Small maodel\n",
    "# loading the lang. model for english and german language and both are small model\n",
    "# This i am using to tokenize the src and trg sequence\n",
    "# My task is MT from german to english so from spacy i am going to download the sm for these langiage so i can apply some #functions to tokenize the data\n",
    "\n",
    "spacy_de=spacy.load('de_core_news_sm')\n",
    "spacy_en=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c381177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, PyTorch uses non-deterministic algorithms to optimize performance.\n",
    "# sometimes this can lead to different results on different runs with the same input.\n",
    "# To ensure reproducibility, we can set the following configurations:\n",
    "\n",
    "SEED=123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f120f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task --> MachineTranslation\n",
    "# src_file --> German sentences\n",
    "# trg_file --> English sentences\n",
    "# load the dataset\n",
    "# here i am using dataset which is in zip format as it needs huge data, Transformer can't be trained of small dataset.\n",
    "\n",
    "# load the dataset\n",
    "# Create a custom dataset class which inherits from PyTorch's Dataset\n",
    "# initialize the dataset with source and target files and optional transformations\n",
    "class Multi30kDataset(Dataset):\n",
    "    def __init__(self,src_file, trg_file, src_transform=None, trg_transform=None):\n",
    "        self.src_data=self.load_data(src_file) #load source data\n",
    "        self.trg_data=self.load_data(trg_file) #load target data\n",
    "        self.src_transform=src_transform       #optional transformation for source data -- Tokenization and lowercase\n",
    "        self.trg_transform=trg_transform       #optional transformation for source data -- Tokenization and lowercase\n",
    "\n",
    "    # function to load data from a gzip file\n",
    "    def load_data(self, file_path):\n",
    "        with gzip.open(file_path, 'rt', encoding = 'utf-8') as f: # open the gzip file at read text mode with encoding utf-8\n",
    "            data = f.readlines() # read all lines from the file\n",
    "        return data # return the list of lines\n",
    "\n",
    "    # return the length of the dataset\n",
    "    #This tells PyTorch how many samples are in your dataset.\n",
    "    def __len__(self):\n",
    "        return len(self.src_data)\n",
    "\n",
    "    # Retrieves the specific data idx-th German and English sentence.\n",
    "    def __getitem__(self, idx):\n",
    "        src_sentence = self.src_data[idx].strip() # get the source sentence at index idx and strip whitespace\n",
    "        trg_sentence = self.trg_data[idx].strip() # get the target sentence at index idx and strip whitespace\n",
    "\n",
    "        # apply transformations if provided\n",
    "        if self.src_transform:\n",
    "            src_sentence = self.src_transform(src_sentence)\n",
    "        if self.trg_transform:\n",
    "            trg_sentence = self.trg_transform(trg_sentence)\n",
    "\n",
    "        return {\"src\": src_sentence, \"trg\": trg_sentence}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0b9238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization and lowercase functions for german language sequence/senstence\n",
    "def tokenize_de(text):\n",
    "    return [token.text.lower() for token in spacy_de.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a610432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization and lowercase functions for english language sequence\n",
    "def tokenize_en(text):\n",
    "    return [token.text.lower() for token in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b2c1b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It defines the file paths for your German–English parallel dataset\n",
    "train_de_path=\"train.de.gz\"\n",
    "train_en_path=\"train.en.gz\"\n",
    "val_de_path=\"val.de.gz\"\n",
    "val_en_path=\"val.en.gz\"\n",
    "test_de_path=\"test_2016_flickr.de.gz\"\n",
    "test_en_path=\"test_2016_flickr.en.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 3 custom data object (Train, validate and test)\n",
    "# each data object reads the corresponding .gz German + English files, tokenize them using corresponding tokenizer\n",
    "# and store stores paired token lists ({\"src\": [...], \"trg\": [...]})\n",
    "train_data = Multi30kDataset(train_de_path, train_en_path, src_transform=tokenize_de, trg_transform=tokenize_en)\n",
    "val_data = Multi30kDataset(val_de_path, val_en_path, src_transform=tokenize_de, trg_transform=tokenize_en)\n",
    "test_data = Multi30kDataset(test_de_path, test_en_path, src_transform=tokenize_de, trg_transform=tokenize_en)\n",
    "\n",
    "\n",
    "# Define special tokens. These 4 special tokens are critical for Transformer-based NLP tasks\n",
    "PAD_TOKEN = '<pad>'\n",
    "SOS_TOKEN = '<sos>'\n",
    "EOS_TOKEN = '<eos>'\n",
    "UNK_TOKEN = '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a simple vocabulary from tokenized sentences.\n",
    "# special tokens come first\n",
    "def create_vocab(tokenized_sentences,special_tokens):\n",
    "    vocab = {token: idx for idx, token in enumerate(special_tokens)}\n",
    "    for sentence in tokenized_sentences:\n",
    "        for token in sentence:\n",
    "            if token not in vocab:\n",
    "                vocab[token] = len(vocab)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7433775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It iterates through all german sentences, removes the extra whitespace and the apply german tokenization\n",
    "# returned list of token of german sentences\n",
    "train_de_tokenized = [tokenize_de(sentence.strip()) for sentence in train_data.src_data]\n",
    "\n",
    "# It iterates through all englis sentences, removes the extra whitespace and the apply english tokenization\n",
    "# returned list of token of English sentences\n",
    "train_en_tokenized = [tokenize_en(sentence.strip()) for sentence in train_data.trg_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d75e91ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.']\n"
     ]
    }
   ],
   "source": [
    "# List of tokens for first german senstence\n",
    "print(train_de_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8aa4bb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n"
     ]
    }
   ],
   "source": [
    "# List of tokens for first englisg senstence\n",
    "print(train_en_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "123c2d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Two seperate vocabulary with special tokens for German and English Language\n",
    "SRC_VOCAB = create_vocab(train_de_tokenized, [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN, UNK_TOKEN])\n",
    "TRG_VOCAB = create_vocab(train_en_tokenized, [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN, UNK_TOKEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c722926f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<sos>': 1,\n",
       " '<eos>': 2,\n",
       " '<unk>': 3,\n",
       " 'zwei': 4,\n",
       " 'junge': 5,\n",
       " 'weiße': 6,\n",
       " 'männer': 7,\n",
       " 'sind': 8,\n",
       " 'im': 9,\n",
       " 'freien': 10,\n",
       " 'in': 11,\n",
       " 'der': 12,\n",
       " 'nähe': 13,\n",
       " 'vieler': 14,\n",
       " 'büsche': 15,\n",
       " '.': 16,\n",
       " 'mehrere': 17,\n",
       " 'mit': 18,\n",
       " 'schutzhelmen': 19,\n",
       " 'bedienen': 20,\n",
       " 'ein': 21,\n",
       " 'antriebsradsystem': 22,\n",
       " 'kleines': 23,\n",
       " 'mädchen': 24,\n",
       " 'klettert': 25,\n",
       " 'spielhaus': 26,\n",
       " 'aus': 27,\n",
       " 'holz': 28,\n",
       " 'mann': 29,\n",
       " 'einem': 30,\n",
       " 'blauen': 31,\n",
       " 'hemd': 32,\n",
       " 'steht': 33,\n",
       " 'auf': 34,\n",
       " 'einer': 35,\n",
       " 'leiter': 36,\n",
       " 'und': 37,\n",
       " 'putzt': 38,\n",
       " 'fenster': 39,\n",
       " 'stehen': 40,\n",
       " 'am': 41,\n",
       " 'herd': 42,\n",
       " 'bereiten': 43,\n",
       " 'essen': 44,\n",
       " 'zu': 45,\n",
       " 'grün': 46,\n",
       " 'hält': 47,\n",
       " 'eine': 48,\n",
       " 'gitarre': 49,\n",
       " ',': 50,\n",
       " 'während': 51,\n",
       " 'andere': 52,\n",
       " 'sein': 53,\n",
       " 'ansieht': 54,\n",
       " 'lächelt': 55,\n",
       " 'einen': 56,\n",
       " 'ausgestopften': 57,\n",
       " 'löwen': 58,\n",
       " 'an': 59,\n",
       " 'schickes': 60,\n",
       " 'spricht': 61,\n",
       " 'dem': 62,\n",
       " 'handy': 63,\n",
       " 'sie': 64,\n",
       " 'langsam': 65,\n",
       " 'die': 66,\n",
       " 'straße': 67,\n",
       " 'entlangschwebt': 68,\n",
       " 'frau': 69,\n",
       " 'großen': 70,\n",
       " 'geldbörse': 71,\n",
       " 'geht': 72,\n",
       " 'tor': 73,\n",
       " 'vorbei': 74,\n",
       " 'jungen': 75,\n",
       " 'tanzen': 76,\n",
       " 'mitten': 77,\n",
       " 'nacht': 78,\n",
       " 'pfosten': 79,\n",
       " 'ballettklasse': 80,\n",
       " 'fünf': 81,\n",
       " 'nacheinander': 82,\n",
       " 'springen': 83,\n",
       " 'vier': 84,\n",
       " 'typen': 85,\n",
       " 'von': 86,\n",
       " 'denen': 87,\n",
       " 'drei': 88,\n",
       " 'hüte': 89,\n",
       " 'tragen': 90,\n",
       " 'nicht': 91,\n",
       " 'oben': 92,\n",
       " 'treppenhaus': 93,\n",
       " 'schwarzer': 94,\n",
       " 'hund': 95,\n",
       " 'gefleckter': 96,\n",
       " 'kämpfen': 97,\n",
       " 'neongrünen': 98,\n",
       " 'orangefarbenen': 99,\n",
       " 'uniform': 100,\n",
       " 'fährt': 101,\n",
       " 'grünen': 102,\n",
       " 'traktor': 103,\n",
       " 'frauen': 104,\n",
       " 'warten': 105,\n",
       " 'stadt': 106,\n",
       " 'schwarzem': 107,\n",
       " 'oberteil': 108,\n",
       " 'brille': 109,\n",
       " 'streut': 110,\n",
       " 'puderzucker': 111,\n",
       " 'gugelhupf': 112,\n",
       " 'sitzt': 113,\n",
       " 'vor': 114,\n",
       " 'gemalten': 115,\n",
       " 'regenbogen': 116,\n",
       " 'liegt': 117,\n",
       " 'bank': 118,\n",
       " 'auch': 119,\n",
       " 'weißer': 120,\n",
       " 'angebunden': 121,\n",
       " 'ist': 122,\n",
       " 'personen': 123,\n",
       " 'sitzen': 124,\n",
       " 'instrumenten': 125,\n",
       " 'kreis': 126,\n",
       " 'gruppe': 127,\n",
       " 'älterer': 128,\n",
       " 'spielt': 129,\n",
       " 'zusammen': 130,\n",
       " 'klarinette': 131,\n",
       " 'notenblättern': 132,\n",
       " 'großes': 133,\n",
       " 'bauwerk': 134,\n",
       " 'kaputt': 135,\n",
       " 'gegangen': 136,\n",
       " 'fahrbahn': 137,\n",
       " 'große': 138,\n",
       " 'menschenmenge': 139,\n",
       " 'außen': 140,\n",
       " 'eingang': 141,\n",
       " 'metrostation': 142,\n",
       " 'tattoo': 143,\n",
       " 'seinem': 144,\n",
       " 'rücken': 145,\n",
       " 'erhält': 146,\n",
       " 'kinder': 147,\n",
       " 'kleinen': 148,\n",
       " 'wippe': 149,\n",
       " 'sand': 150,\n",
       " 'reflektierende': 151,\n",
       " 'weste': 152,\n",
       " 'schutzhelm': 153,\n",
       " 'trägt': 154,\n",
       " 'flagge': 155,\n",
       " 'person': 156,\n",
       " 'mantel': 157,\n",
       " 'belebten': 158,\n",
       " 'gehweg': 159,\n",
       " 'betrachtet': 160,\n",
       " 'gemälde': 161,\n",
       " 'straßenszene': 162,\n",
       " 'hosen': 163,\n",
       " 'läuft': 164,\n",
       " 'entlang': 165,\n",
       " 'das': 166,\n",
       " 'kleine': 167,\n",
       " 'kind': 168,\n",
       " 'roten': 169,\n",
       " 'seilen': 170,\n",
       " 'spielplatz': 171,\n",
       " 'du': 172,\n",
       " 'weißt': 173,\n",
       " 'dass': 174,\n",
       " 'ich': 175,\n",
       " 'aussehe': 176,\n",
       " 'wie': 177,\n",
       " 'justin': 178,\n",
       " 'bieber': 179,\n",
       " 'junger': 180,\n",
       " 'schwarz-gelben': 181,\n",
       " 'jacke': 182,\n",
       " 'blickt': 183,\n",
       " 'etwas': 184,\n",
       " 'tasse': 185,\n",
       " 'kaffee': 186,\n",
       " 'urinal': 187,\n",
       " 'gehende': 188,\n",
       " 'mehrfarbigen': 189,\n",
       " 'himmel': 190,\n",
       " 'hintergrund': 191,\n",
       " 'alter': 192,\n",
       " 'allein': 193,\n",
       " 'bier': 194,\n",
       " 'trinkt': 195,\n",
       " 'geschulter': 196,\n",
       " 'polizeihund': 197,\n",
       " 'neben': 198,\n",
       " 'hundeführer': 199,\n",
       " 'polizeitransporter': 200,\n",
       " 'verschneiten': 201,\n",
       " 'fahrrad': 202,\n",
       " 'alle': 203,\n",
       " 'hemden': 204,\n",
       " 'krawatten': 205,\n",
       " 'schwarze': 206,\n",
       " 'freizeithosen': 207,\n",
       " 'unterhalten': 208,\n",
       " 'sich': 209,\n",
       " 'hinter': 210,\n",
       " 'lieferwagen': 211,\n",
       " 'nach': 212,\n",
       " 'hinten': 213,\n",
       " 'gerichteten': 214,\n",
       " 'hut': 215,\n",
       " 'arbeitet': 216,\n",
       " 'maschinen': 217,\n",
       " 'arbeiten': 218,\n",
       " 'fabrikumgebung': 219,\n",
       " 'packen': 220,\n",
       " 'gläser': 221,\n",
       " 'kerzen': 222,\n",
       " 'kartons': 223,\n",
       " 'asiatischer': 224,\n",
       " 'kehrt': 225,\n",
       " 'den': 226,\n",
       " 'lehnt': 227,\n",
       " 'auto': 228,\n",
       " 'um': 229,\n",
       " 'fahrer': 230,\n",
       " 'reden': 231,\n",
       " 'zusieht': 232,\n",
       " 'kleinkinder': 233,\n",
       " 'gras': 234,\n",
       " 'leute': 235,\n",
       " 'sehen': 236,\n",
       " 'seltsamen': 237,\n",
       " 'fahrzeug': 238,\n",
       " 'platz': 239,\n",
       " 'silbernen': 240,\n",
       " 'schöne': 241,\n",
       " 'braut': 242,\n",
       " 'ihrem': 243,\n",
       " 'neuen': 244,\n",
       " 'ehemann': 245,\n",
       " 'kleiner': 246,\n",
       " 'bei': 247,\n",
       " \"mcdonald's\": 248,\n",
       " 'gamecube': 249,\n",
       " 'schüttelt': 250,\n",
       " 'rande': 251,\n",
       " 'eines': 252,\n",
       " 'strands': 253,\n",
       " 'ball': 254,\n",
       " 'park': 255,\n",
       " 'grillen': 256,\n",
       " 'sonnenbrille': 257,\n",
       " 'legt': 258,\n",
       " 'seinen': 259,\n",
       " 'arm': 260,\n",
       " 'schwarz-weißen': 261,\n",
       " 'bluse': 262,\n",
       " 'luftballonhut': 263,\n",
       " 'picknicktischen': 264,\n",
       " 'taekwondo-wettbewerbs': 265,\n",
       " 'sprungtritt': 266,\n",
       " 'über': 267,\n",
       " 'macht': 268,\n",
       " 'dabei': 269,\n",
       " 'tritt': 270,\n",
       " 'wasser': 271,\n",
       " 'weißen': 272,\n",
       " 'gießt': 273,\n",
       " 'sonne': 274,\n",
       " 'schützt': 275,\n",
       " 'versucht': 276,\n",
       " 'stück': 277,\n",
       " 'papier': 278,\n",
       " 'lesen': 279,\n",
       " 'kindern': 280,\n",
       " 'laufen': 281,\n",
       " 'overall': 282,\n",
       " 'steinwand': 283,\n",
       " 'springt': 284,\n",
       " 'baumstamm': 285,\n",
       " 'anzug': 286,\n",
       " 'rennt': 287,\n",
       " 'anderen': 288,\n",
       " 'herren': 289,\n",
       " 'herum': 290,\n",
       " 'barfuß': 291,\n",
       " 'olivgrüne': 292,\n",
       " 'kurze': 293,\n",
       " 'propangasgrill': 294,\n",
       " 'hotdogs': 295,\n",
       " 'grillt': 296,\n",
       " 'gleichzeitig': 297,\n",
       " 'blaue': 298,\n",
       " 'kunststofftasse': 299,\n",
       " 'schnee': 300,\n",
       " 'wartet': 301,\n",
       " 'bis': 302,\n",
       " 'ampel': 303,\n",
       " 'wird': 304,\n",
       " 'skiern': 305,\n",
       " 'verkaufende': 306,\n",
       " 'kunstwerke': 307,\n",
       " 'sieben': 308,\n",
       " 'kletterer': 309,\n",
       " 'klettern': 310,\n",
       " 'felswand': 311,\n",
       " 'hoch': 312,\n",
       " 'anderer': 313,\n",
       " 'dasteht': 314,\n",
       " 'seil': 315,\n",
       " 'gelenkige': 316,\n",
       " 'körper': 317,\n",
       " 'des': 318,\n",
       " 'turners': 319,\n",
       " 'schwebt': 320,\n",
       " 'schwebebalken': 321,\n",
       " 'schiebt': 322,\n",
       " 'spielzeug-geländefahrzeug': 323,\n",
       " 'gummi-pool': 324,\n",
       " 'windjacke': 325,\n",
       " 'dach': 326,\n",
       " 'installiertes': 327,\n",
       " 'fernrohr': 328,\n",
       " 'darunterliegende': 329,\n",
       " 'objekt': 330,\n",
       " 'flugzeug': 331,\n",
       " 'aussieht': 332,\n",
       " 'schlauch': 333,\n",
       " 'posieren': 334,\n",
       " 'glücklich': 335,\n",
       " 'einkaufswagen': 336,\n",
       " 'supermarkt': 337,\n",
       " 'kurz': 338,\n",
       " 'davor': 339,\n",
       " 'gelbes': 340,\n",
       " 'hundespielzeug': 341,\n",
       " 'fangen': 342,\n",
       " 'kerl': 343,\n",
       " 'dessen': 344,\n",
       " 'hand': 345,\n",
       " 'teil': 346,\n",
       " 'seines': 347,\n",
       " 'gesichts': 348,\n",
       " 'bedeckt': 349,\n",
       " 'nische': 350,\n",
       " 'restaurant': 351,\n",
       " 'schwarz-weißer': 352,\n",
       " 'spring': 353,\n",
       " 'gelben': 354,\n",
       " 'spielzeug': 355,\n",
       " 'wanderer': 356,\n",
       " 'machen': 357,\n",
       " 'stückchen': 358,\n",
       " 'pause': 359,\n",
       " 'führt': 360,\n",
       " 'seine': 361,\n",
       " 'neue': 362,\n",
       " 'hölzerne': 363,\n",
       " 'kreation': 364,\n",
       " 'vater': 365,\n",
       " 'erwachsener': 366,\n",
       " 'sohn': 367,\n",
       " 'camping-ausflug': 368,\n",
       " 'wildnis': 369,\n",
       " 'reisender': 370,\n",
       " 'bart': 371,\n",
       " 'karte': 372,\n",
       " 'liest': 373,\n",
       " 'winkt': 374,\n",
       " 'ente': 375,\n",
       " 'umgeben': 376,\n",
       " 'grünanlage': 377,\n",
       " 'paar': 378,\n",
       " 'baby': 379,\n",
       " 'sportwagen': 380,\n",
       " 'gebäude': 381,\n",
       " 'parkenden': 382,\n",
       " 'durch': 383,\n",
       " 'bohrt': 384,\n",
       " 'gefrorene': 385,\n",
       " 'eis': 386,\n",
       " 'teichs': 387,\n",
       " 'lohfarbene': 388,\n",
       " 'hunde': 389,\n",
       " 'spielen': 390,\n",
       " 'sandigen': 391,\n",
       " 'strand': 392,\n",
       " 'blau': 393,\n",
       " 'rot': 394,\n",
       " 'pickeln': 395,\n",
       " 'eisklettert': 396,\n",
       " 'pfad': 397,\n",
       " 'wiese': 398,\n",
       " 'gehen': 399,\n",
       " 'schwarz': 400,\n",
       " 'schaufelt': 401,\n",
       " 'ignoriert': 402,\n",
       " 'öffentliche': 403,\n",
       " 'sicherheit': 404,\n",
       " 'seiner': 405,\n",
       " 'hochzeitstorte': 406,\n",
       " 'nasser': 407,\n",
       " 'grünes': 408,\n",
       " 'dorfbewohner': 409,\n",
       " 'verkaufen': 410,\n",
       " 'ihre': 411,\n",
       " 'ernte': 412,\n",
       " 'markt': 413,\n",
       " 'vollen': 414,\n",
       " 'konzert': 415,\n",
       " 'nähert': 416,\n",
       " 'hauptsänger': 417,\n",
       " 'skateboard': 418,\n",
       " 'sieht': 419,\n",
       " 'befinden': 420,\n",
       " 'kajak': 421,\n",
       " 'ihnen': 422,\n",
       " 'baustelle': 423,\n",
       " 'arbeitenden': 424,\n",
       " 'männern': 425,\n",
       " 'reklamefläche': 426,\n",
       " 'werbung': 427,\n",
       " 'für': 428,\n",
       " 'brillen': 429,\n",
       " 'jugendlicher': 430,\n",
       " 'schwenkt': 431,\n",
       " 'fahnen': 432,\n",
       " 'farbspektrum': 433,\n",
       " 'zeigen': 434,\n",
       " 'alte': 435,\n",
       " 'er': 436,\n",
       " 'fisch': 437,\n",
       " 'zubereitet': 438,\n",
       " 'pullunder': 439,\n",
       " 'wallenden': 440,\n",
       " 'rock': 441,\n",
       " 'lied': 442,\n",
       " 'singend': 443,\n",
       " 'bühne': 444,\n",
       " 'treppenstufen': 445,\n",
       " 'brauner': 446,\n",
       " 'labrador': 447,\n",
       " 'wobei': 448,\n",
       " 'maul': 449,\n",
       " 'hat': 450,\n",
       " 'männlicher': 451,\n",
       " 'hockey-goalie': 452,\n",
       " 'roter': 453,\n",
       " 'duckt': 454,\n",
       " 'stock': 455,\n",
       " 'beim': 456,\n",
       " 'rucksack': 457,\n",
       " 'hof': 458,\n",
       " 'gebäudes': 459,\n",
       " 'skulptur': 460,\n",
       " 'männliches': 461,\n",
       " 'kleinkind': 462,\n",
       " 'geländer': 463,\n",
       " 'festhält': 464,\n",
       " 'kniet': 465,\n",
       " 'hochhaus': 466,\n",
       " 'ihr': 467,\n",
       " 'örtlichen': 468,\n",
       " 'spazieren': 469,\n",
       " 'obst': 470,\n",
       " 'blondhaariger': 471,\n",
       " 'dunkelhaariges': 472,\n",
       " 'kindertisch': 473,\n",
       " 'isst': 474,\n",
       " 'draußen': 475,\n",
       " 'tisch': 476,\n",
       " 'elektrogitarre': 477,\n",
       " 'softball': 478,\n",
       " 'schlägt': 479,\n",
       " 'fast': 480,\n",
       " 'senkrecht': 481,\n",
       " 'unten': 482,\n",
       " 'schwarzen': 483,\n",
       " 'schwarzes': 484,\n",
       " 'städtischen': 485,\n",
       " 'umgebung': 486,\n",
       " 'beton': 487,\n",
       " 'glättet': 488,\n",
       " 'hübschen': 489,\n",
       " 'decke': 490,\n",
       " 'einzelner': 491,\n",
       " 'abends': 492,\n",
       " 'brücke': 493,\n",
       " 'grüne': 494,\n",
       " 'bohnen': 495,\n",
       " 'grill': 496,\n",
       " 'felsvorsprung': 497,\n",
       " 'bergen': 498,\n",
       " 'rast': 499,\n",
       " 'viele': 500,\n",
       " 'menschen': 501,\n",
       " 'überqueren': 502,\n",
       " 'sehr': 503,\n",
       " 'hohe': 504,\n",
       " 'fußbrücke': 505,\n",
       " 'baumbewachsenen': 506,\n",
       " 'hügel': 507,\n",
       " 'ansammlung': 508,\n",
       " 'schlauchbooten': 509,\n",
       " 'blonde': 510,\n",
       " 'händchen': 511,\n",
       " 'halten': 512,\n",
       " 'grauem': 513,\n",
       " 'haar': 514,\n",
       " 'stuhl': 515,\n",
       " 'instrument': 516,\n",
       " 'bambus': 517,\n",
       " 'malt': 518,\n",
       " 'ziegel': 519,\n",
       " 'dreißigern': 520,\n",
       " 'u-bahn': 521,\n",
       " 'telefon': 522,\n",
       " 'fußgängerübergang': 523,\n",
       " 'bus': 524,\n",
       " 'leuten': 525,\n",
       " 'nudeln': 526,\n",
       " 'meeres': 527,\n",
       " 'schale': 528,\n",
       " 'voller': 529,\n",
       " 'ihrer': 530,\n",
       " 'typ': 531,\n",
       " 'loch': 532,\n",
       " 'lächeln': 533,\n",
       " 'viel': 534,\n",
       " 'groß': 535,\n",
       " 'männlich': 536,\n",
       " 'weiblich': 537,\n",
       " 'waldgebiet': 538,\n",
       " 'wanne': 539,\n",
       " 'schlafenden': 540,\n",
       " 'jemandem': 541,\n",
       " 'outfit': 542,\n",
       " 'rosafarbenen': 543,\n",
       " 'streifen': 544,\n",
       " 'mitglied': 545,\n",
       " 'afrikanischen': 546,\n",
       " 'stamms': 547,\n",
       " 'stammeskleidung': 548,\n",
       " 'konzentriert': 549,\n",
       " 'kamera': 550,\n",
       " 'samurai-krieger': 551,\n",
       " 'ganz': 552,\n",
       " 'übungsmatte': 553,\n",
       " 'nimmt': 554,\n",
       " 'schwert': 555,\n",
       " 'scheide': 556,\n",
       " 'überfüllten': 557,\n",
       " 'richtung': 558,\n",
       " 'weg': 559,\n",
       " 'steiniges': 560,\n",
       " 'flussbett': 561,\n",
       " 'wachmann': 562,\n",
       " 'beleuchteten': 563,\n",
       " 'metallskulptur': 564,\n",
       " 'violett': 565,\n",
       " 'gehsteig': 566,\n",
       " 'abwaschen': 567,\n",
       " 'ducken': 568,\n",
       " 'büschen': 569,\n",
       " 'sprechen': 570,\n",
       " 'telefone': 571,\n",
       " 'junges': 572,\n",
       " 'mehrfarbig': 573,\n",
       " 'gekleidet': 574,\n",
       " 'rechten': 575,\n",
       " 'haus': 576,\n",
       " 'leuchtend': 577,\n",
       " 'boden': 578,\n",
       " 'kunststück': 579,\n",
       " 'skateboarder': 580,\n",
       " 'lachen': 581,\n",
       " 'flasche': 582,\n",
       " 'streckt': 583,\n",
       " 'schütteln': 584,\n",
       " 'kommuniziert': 585,\n",
       " 'walkie-talkie': 586,\n",
       " 'fluss': 587,\n",
       " 'hinunterpaddelt': 588,\n",
       " 'gesehen': 589,\n",
       " 'zöpfen': 590,\n",
       " 'pullovern': 591,\n",
       " 'restauranttisch': 592,\n",
       " 'mahlzeit': 593,\n",
       " 'bauarbeiter': 594,\n",
       " 'stahlbalken': 595,\n",
       " 'strahlend': 596,\n",
       " 'teig': 597,\n",
       " 'schüssel': 598,\n",
       " 'rührt': 599,\n",
       " 'sonnigen': 600,\n",
       " 'tag': 601,\n",
       " 'luftballon': 602,\n",
       " 'matsch': 603,\n",
       " 'broschüre': 604,\n",
       " 'zugfahrten': 605,\n",
       " 'fußweg': 606,\n",
       " 'joggen': 607,\n",
       " 'sprungturm': 608,\n",
       " ' ': 609,\n",
       " 'hohen': 610,\n",
       " 'brett': 611,\n",
       " 'schwimmbecken': 612,\n",
       " 'hell': 613,\n",
       " 'gefärbter': 614,\n",
       " 'räkelt': 615,\n",
       " 'hölzernen': 616,\n",
       " 'wasserbehälter': 617,\n",
       " 'schläft': 618,\n",
       " 'bushaltestelle': 619,\n",
       " 'jeans': 620,\n",
       " 'baum': 621,\n",
       " 'anderes': 622,\n",
       " 'schlafender': 623,\n",
       " 'fahrenden': 624,\n",
       " 'befindet': 625,\n",
       " 'unter': 626,\n",
       " 'wohnungsküche': 627,\n",
       " 'wirft': 628,\n",
       " 'pfannkuchen': 629,\n",
       " 'feuerwehrleute': 630,\n",
       " 'reagieren': 631,\n",
       " 'alarm': 632,\n",
       " 'löschfahrzeuge': 633,\n",
       " 'booten': 634,\n",
       " 'ufer': 635,\n",
       " 'schutzwesten': 636,\n",
       " 'zeitungsverkäufer': 637,\n",
       " 'farbenfrohen': 638,\n",
       " 'zusammenstellung': 639,\n",
       " 'zeitschriften': 640,\n",
       " 'blaues': 641,\n",
       " 'jeanslatzhose': 642,\n",
       " 'bäckerei': 643,\n",
       " 'dicke': 644,\n",
       " 'bäcker': 645,\n",
       " 'lehrling': 646,\n",
       " 'ihm': 647,\n",
       " 'mehl': 648,\n",
       " 'augen': 649,\n",
       " 'reibt': 650,\n",
       " 'nacktem': 651,\n",
       " 'oberkörper': 652,\n",
       " 'tropischen': 653,\n",
       " 'schatten': 654,\n",
       " 'badehosen': 655,\n",
       " 'skifahrer': 656,\n",
       " 'schneebedeckten': 657,\n",
       " 'berg': 658,\n",
       " 'rotes': 659,\n",
       " 'erdhügel': 660,\n",
       " 'zweiradfahrer': 661,\n",
       " 'rennen': 662,\n",
       " 'biegen': 663,\n",
       " 'scharf': 664,\n",
       " 'links': 665,\n",
       " 'ab': 666,\n",
       " 'fahren': 667,\n",
       " 'sandhügel': 668,\n",
       " 'mitte': 669,\n",
       " 'beugt': 670,\n",
       " 'mannes': 671,\n",
       " 'arzt': 672,\n",
       " 'pflegekräfte': 673,\n",
       " 'blauer': 674,\n",
       " 'arbeitskleidung': 675,\n",
       " 'führen': 676,\n",
       " 'operation': 677,\n",
       " 'flauschiger': 678,\n",
       " 'dobermann': 679,\n",
       " 'hinterher': 680,\n",
       " 'da': 681,\n",
       " 'nachdem': 682,\n",
       " 'bowlingkugel': 683,\n",
       " 'bahn': 684,\n",
       " 'geworfen': 685,\n",
       " 'wettergegerbter': 686,\n",
       " 'reitet': 687,\n",
       " 'schönen': 688,\n",
       " 'esel': 689,\n",
       " 'felsen': 690,\n",
       " 'couch': 691,\n",
       " 'schläfchen': 692,\n",
       " 'speer': 693,\n",
       " 'nachts': 694,\n",
       " 'ballons': 695,\n",
       " 'schulter': 696,\n",
       " 'zeitschrift': 697,\n",
       " 'hocke': 698,\n",
       " 'anzuzünden': 699,\n",
       " 'belebte': 700,\n",
       " 'einkaufszentrum': 701,\n",
       " 'verdunkelten': 702,\n",
       " 'raum': 703,\n",
       " 'hunden': 704,\n",
       " 'seifenschaum': 705,\n",
       " 'bedeckter': 706,\n",
       " 'bekommt': 707,\n",
       " 'gesicht': 708,\n",
       " 'abgewischt': 709,\n",
       " 'dutzende': 710,\n",
       " 'feiern': 711,\n",
       " 'boot': 712,\n",
       " 'hellen': 713,\n",
       " 'bikini': 714,\n",
       " 'cowboy-hut': 715,\n",
       " 'stroh': 716,\n",
       " 'rutscht': 717,\n",
       " 'rutsche': 718,\n",
       " 'farbigen': 719,\n",
       " 'rohren': 720,\n",
       " 'herunter': 721,\n",
       " 'taucheranzug': 722,\n",
       " 'krabbelkind': 723,\n",
       " 'luft': 724,\n",
       " 'bereit': 725,\n",
       " 'es': 726,\n",
       " 'aufzufangen': 727,\n",
       " 'lkw': 728,\n",
       " 'ländliche': 729,\n",
       " 'köche': 730,\n",
       " 'restaurantküche': 731,\n",
       " 'hamburger': 732,\n",
       " 'schneiden': 733,\n",
       " 'grimassen': 734,\n",
       " 'braunen': 735,\n",
       " 'eingezäunten': 736,\n",
       " 'bereich': 737,\n",
       " 'funken': 738,\n",
       " 'fliegen': 739,\n",
       " 'kreuz': 740,\n",
       " 'arbeitende': 741,\n",
       " 'schaufeln': 742,\n",
       " 'gleis': 743,\n",
       " 'pferde': 744,\n",
       " 'eingedämmten': 745,\n",
       " 'feuers': 746,\n",
       " 'arbeiter': 747,\n",
       " 'warnwesten': 748,\n",
       " 'zugwaggons': 749,\n",
       " 'klassischen': 750,\n",
       " 'schlichten': 751,\n",
       " 'volkswagen': 752,\n",
       " 'käfer': 753,\n",
       " 'baut': 754,\n",
       " 'metallrahmen': 755,\n",
       " 'starren': 756,\n",
       " 'dock': 757,\n",
       " 'maschine': 758,\n",
       " 'ausbessert': 759,\n",
       " 'rötlichem': 760,\n",
       " 'mascara': 761,\n",
       " 'wimpern': 762,\n",
       " 'kopf': 763,\n",
       " 'shorts': 764,\n",
       " 'halle': 765,\n",
       " 'motorroller': 766,\n",
       " 'geparkt': 767,\n",
       " 'polizeihubschrauber': 768,\n",
       " 'parks': 769,\n",
       " 'bereitet': 770,\n",
       " 'landung': 771,\n",
       " 'warnweste': 772,\n",
       " 'bringt': 773,\n",
       " 'gerüst': 774,\n",
       " 'position': 775,\n",
       " 'vierzehn': 776,\n",
       " 'bestehende': 777,\n",
       " 'esstischen': 778,\n",
       " 'versammelt': 779,\n",
       " 'teenager': 780,\n",
       " 'aufblasbaren': 781,\n",
       " 'familie': 782,\n",
       " 'ältere': 783,\n",
       " 'brät': 784,\n",
       " 'küche': 785,\n",
       " 'pfanne': 786,\n",
       " 'extravagante': 787,\n",
       " 'feder-kopfschmuck': 788,\n",
       " 'kommt': 789,\n",
       " 'waldland': 790,\n",
       " 'grünem': 791,\n",
       " 'offenen': 792,\n",
       " 'veranda': 793,\n",
       " 'handtasche': 794,\n",
       " 'tür': 795,\n",
       " 'formulare': 796,\n",
       " 'ausfüllt': 797,\n",
       " 'kreuzung': 798,\n",
       " 'lilafarben': 799,\n",
       " 'mieder': 800,\n",
       " 'faltet': 801,\n",
       " 'hände': 802,\n",
       " 'schoß': 803,\n",
       " 'mutter': 804,\n",
       " 'fischen': 805,\n",
       " 'strandpromenade': 806,\n",
       " 'sechs': 807,\n",
       " 'männliche': 808,\n",
       " 'spiel': 809,\n",
       " 'paddeln': 810,\n",
       " 'lacht': 811,\n",
       " 'motor': 812,\n",
       " 'alten': 813,\n",
       " 'antiken': 814,\n",
       " 'autos': 815,\n",
       " 'gelber': 816,\n",
       " 'benzinkanister': 817,\n",
       " 'wassernähe': 818,\n",
       " 'braunes': 819,\n",
       " 'pony': 820,\n",
       " 'ziehen': 821,\n",
       " 'gelenkten': 822,\n",
       " 'wagen': 823,\n",
       " 'untergrund': 824,\n",
       " 'steile': 825,\n",
       " 'verwendet': 826,\n",
       " 'dazu': 827,\n",
       " 'wandergruppe': 828,\n",
       " 'kalkstein': 829,\n",
       " 'erwachsenen': 830,\n",
       " 'so': 831,\n",
       " 'tut': 832,\n",
       " 'als': 833,\n",
       " 'ob': 834,\n",
       " 'ins': 835,\n",
       " 'gerade': 836,\n",
       " 'satz': 837,\n",
       " 'unterricht': 838,\n",
       " 'wort': 839,\n",
       " 'melden': 840,\n",
       " 'badehose': 841,\n",
       " 'betonplattform': 842,\n",
       " 'gewässer': 843,\n",
       " 'nähmaschine': 844,\n",
       " 'präzise': 845,\n",
       " 'dame': 846,\n",
       " 't-shirt': 847,\n",
       " 'ihren': 848,\n",
       " 'farm': 849,\n",
       " 'paprika': 850,\n",
       " 'verkauft': 851,\n",
       " 'rasen': 852,\n",
       " 'blasen': 853,\n",
       " 'geblasen': 854,\n",
       " 'hindernisstrecke': 855,\n",
       " 'tunnel': 856,\n",
       " 'heraus': 857,\n",
       " 'erdboden': 858,\n",
       " 'badeanzug': 859,\n",
       " 'blumenaufdruck': 860,\n",
       " 'meer': 861,\n",
       " 'reihe': 862,\n",
       " 'farbenfroher': 863,\n",
       " 'pool': 864,\n",
       " 'schwimmbad': 865,\n",
       " 'diskutieren': 866,\n",
       " 'schneemobil-tour': 867,\n",
       " 'daran': 868,\n",
       " 'entfernen': 869,\n",
       " 'klappstuhl': 870,\n",
       " 'stapel': 871,\n",
       " 'dämmerung': 872,\n",
       " 'städtische': 873,\n",
       " 'haaren': 874,\n",
       " 'bläst': 875,\n",
       " 'blütenblätter': 876,\n",
       " 'blume': 877,\n",
       " 'geländewagen': 878,\n",
       " 'allradfahrzeug': 879,\n",
       " 'fliegt': 880,\n",
       " 'dunklen': 881,\n",
       " 'geben': 882,\n",
       " 'spachtel': 883,\n",
       " 'essbares': 884,\n",
       " 'eisenpfanne': 885,\n",
       " 'umarmen': 886,\n",
       " 'hinterteil': 887,\n",
       " 'kuh': 888,\n",
       " 'schiff': 889,\n",
       " 'wo': 890,\n",
       " 'ankunft': 891,\n",
       " 'erwarten': 892,\n",
       " 'sandalen': 893,\n",
       " 'uns': 894,\n",
       " 'singt': 895,\n",
       " 'mikrophon': 896,\n",
       " 'reiten': 897,\n",
       " 'elefanten': 898,\n",
       " 'hausähnlichen': 899,\n",
       " 'gebäuden': 900,\n",
       " 'bäumen': 901,\n",
       " 'mexikanischer': 902,\n",
       " 'motorhaube': 903,\n",
       " 'lkws': 904,\n",
       " 'rothaariges': 905,\n",
       " 'menschengruppe': 906,\n",
       " 'sammelt': 907,\n",
       " 'verschieden': 908,\n",
       " 'weißes': 909,\n",
       " 'weint': 910,\n",
       " 'wegen': 911,\n",
       " 'umgekippten': 912,\n",
       " 'spielzeugs': 913,\n",
       " 'fußballplatz': 914,\n",
       " 'fußball': 915,\n",
       " 'gefriergerät': 916,\n",
       " 'absticht': 917,\n",
       " 'hockern': 918,\n",
       " 'ausgebreitete': 919,\n",
       " 'amerikanische': 920,\n",
       " 'fahne': 921,\n",
       " 'falsche': 922,\n",
       " 'zeigt': 923,\n",
       " 'bild': 924,\n",
       " 'radfahrer': 925,\n",
       " 'kurvigen': 926,\n",
       " 'hinauf': 927,\n",
       " 'jeansjacke': 928,\n",
       " 'feld': 929,\n",
       " 'blauem': 930,\n",
       " 'daumen': 931,\n",
       " 'küssendes': 932,\n",
       " 'aufzug': 933,\n",
       " 'fußballspieler': 934,\n",
       " 'fußballdress': 935,\n",
       " 'händen': 936,\n",
       " 'teamkollegen': 937,\n",
       " 'aufgehalten': 938,\n",
       " 'spieler': 939,\n",
       " 'gegnerischen': 940,\n",
       " 'mannschaft': 941,\n",
       " 'greift': 942,\n",
       " 'bauen': 943,\n",
       " 'wand': 944,\n",
       " 'wüste': 945,\n",
       " 'freunden': 946,\n",
       " 'gesichtsfarbe': 947,\n",
       " 'federstirnbändern': 948,\n",
       " 'umhängetasche': 949,\n",
       " 'jackett': 950,\n",
       " 'seilspielzeug': 951,\n",
       " 'altmodische': 952,\n",
       " 'videokamera': 953,\n",
       " 'komischer': 954,\n",
       " 'kleidung': 955,\n",
       " 'flippigen': 956,\n",
       " 'teams': 957,\n",
       " 'verhindern': 958,\n",
       " 'tagsüber': 959,\n",
       " 'schürze': 960,\n",
       " 'bordsteinkante': 961,\n",
       " 'braun-weißer': 962,\n",
       " 'frisbee-scheibe': 963,\n",
       " 'zuschauer': 964,\n",
       " 'zusehen': 965,\n",
       " 'tennisspieler': 966,\n",
       " 'tennisanlage': 967,\n",
       " 'jongleure': 968,\n",
       " 'fackeln': 969,\n",
       " 'vorführung': 970,\n",
       " 'dichte': 971,\n",
       " 'stufen': 972,\n",
       " 'ohne': 973,\n",
       " 'schuhe': 974,\n",
       " 'glatten': 975,\n",
       " 'steinen': 976,\n",
       " 'gap-hut': 977,\n",
       " 'dummes': 978,\n",
       " 'kindes': 979,\n",
       " 'aufhängen': 980,\n",
       " 'speedo-oberteil': 981,\n",
       " 'schutzbrille': 982,\n",
       " 'atem': 983,\n",
       " 'vielbefahrene': 984,\n",
       " 'damen': 985,\n",
       " 'kartenspiel': 986,\n",
       " 'trinken': 987,\n",
       " 'genießen': 988,\n",
       " 'zusammenkunft': 989,\n",
       " 'pabst': 990,\n",
       " 'blue': 991,\n",
       " 'ribbon': 992,\n",
       " 'diet': 993,\n",
       " 'coke': 994,\n",
       " 'schuhen': 995,\n",
       " 'weißem': 996,\n",
       " 'grauen': 997,\n",
       " 'froschskulptur': 998,\n",
       " 'zeitung': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC_VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "394db92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<sos>': 1,\n",
       " '<eos>': 2,\n",
       " '<unk>': 3,\n",
       " 'two': 4,\n",
       " 'young': 5,\n",
       " ',': 6,\n",
       " 'white': 7,\n",
       " 'males': 8,\n",
       " 'are': 9,\n",
       " 'outside': 10,\n",
       " 'near': 11,\n",
       " 'many': 12,\n",
       " 'bushes': 13,\n",
       " '.': 14,\n",
       " 'several': 15,\n",
       " 'men': 16,\n",
       " 'in': 17,\n",
       " 'hard': 18,\n",
       " 'hats': 19,\n",
       " 'operating': 20,\n",
       " 'a': 21,\n",
       " 'giant': 22,\n",
       " 'pulley': 23,\n",
       " 'system': 24,\n",
       " 'little': 25,\n",
       " 'girl': 26,\n",
       " 'climbing': 27,\n",
       " 'into': 28,\n",
       " 'wooden': 29,\n",
       " 'playhouse': 30,\n",
       " 'man': 31,\n",
       " 'blue': 32,\n",
       " 'shirt': 33,\n",
       " 'is': 34,\n",
       " 'standing': 35,\n",
       " 'on': 36,\n",
       " 'ladder': 37,\n",
       " 'cleaning': 38,\n",
       " 'window': 39,\n",
       " 'at': 40,\n",
       " 'the': 41,\n",
       " 'stove': 42,\n",
       " 'preparing': 43,\n",
       " 'food': 44,\n",
       " 'green': 45,\n",
       " 'holds': 46,\n",
       " 'guitar': 47,\n",
       " 'while': 48,\n",
       " 'other': 49,\n",
       " 'observes': 50,\n",
       " 'his': 51,\n",
       " 'smiling': 52,\n",
       " 'stuffed': 53,\n",
       " 'lion': 54,\n",
       " 'trendy': 55,\n",
       " 'talking': 56,\n",
       " 'her': 57,\n",
       " 'cellphone': 58,\n",
       " 'gliding': 59,\n",
       " 'slowly': 60,\n",
       " 'down': 61,\n",
       " 'street': 62,\n",
       " 'woman': 63,\n",
       " 'with': 64,\n",
       " 'large': 65,\n",
       " 'purse': 66,\n",
       " 'walking': 67,\n",
       " 'by': 68,\n",
       " 'gate': 69,\n",
       " 'boys': 70,\n",
       " 'dancing': 71,\n",
       " 'poles': 72,\n",
       " 'middle': 73,\n",
       " 'of': 74,\n",
       " 'night': 75,\n",
       " 'ballet': 76,\n",
       " 'class': 77,\n",
       " 'five': 78,\n",
       " 'girls': 79,\n",
       " 'jumping': 80,\n",
       " 'sequence': 81,\n",
       " 'four': 82,\n",
       " 'guys': 83,\n",
       " 'three': 84,\n",
       " 'wearing': 85,\n",
       " 'one': 86,\n",
       " 'not': 87,\n",
       " 'top': 88,\n",
       " 'staircase': 89,\n",
       " 'black': 90,\n",
       " 'dog': 91,\n",
       " 'and': 92,\n",
       " 'spotted': 93,\n",
       " 'fighting': 94,\n",
       " 'neon': 95,\n",
       " 'orange': 96,\n",
       " 'uniform': 97,\n",
       " 'driving': 98,\n",
       " 'tractor': 99,\n",
       " 'women': 100,\n",
       " 'wait': 101,\n",
       " 'city': 102,\n",
       " 'lady': 103,\n",
       " 'glasses': 104,\n",
       " 'sprinkling': 105,\n",
       " 'powdered': 106,\n",
       " 'sugar': 107,\n",
       " 'bundt': 108,\n",
       " 'cake': 109,\n",
       " 'sitting': 110,\n",
       " 'front': 111,\n",
       " 'painted': 112,\n",
       " 'rainbow': 113,\n",
       " 'lays': 114,\n",
       " 'bench': 115,\n",
       " 'to': 116,\n",
       " 'which': 117,\n",
       " 'also': 118,\n",
       " 'tied': 119,\n",
       " 'people': 120,\n",
       " 'circle': 121,\n",
       " 'instruments': 122,\n",
       " 'bunch': 123,\n",
       " 'elderly': 124,\n",
       " 'play': 125,\n",
       " 'their': 126,\n",
       " 'clarinets': 127,\n",
       " 'together': 128,\n",
       " 'as': 129,\n",
       " 'they': 130,\n",
       " 'read': 131,\n",
       " 'off': 132,\n",
       " 'sheet': 133,\n",
       " 'music': 134,\n",
       " 'structure': 135,\n",
       " 'has': 136,\n",
       " 'broken': 137,\n",
       " 'laying': 138,\n",
       " 'roadway': 139,\n",
       " 'crowd': 140,\n",
       " 'stand': 141,\n",
       " 'entrance': 142,\n",
       " 'metro': 143,\n",
       " 'station': 144,\n",
       " 'getting': 145,\n",
       " 'tattoo': 146,\n",
       " 'back': 147,\n",
       " 'children': 148,\n",
       " 'sit': 149,\n",
       " 'small': 150,\n",
       " 'seesaw': 151,\n",
       " 'sand': 152,\n",
       " 'reflective': 153,\n",
       " 'vest': 154,\n",
       " 'hat': 155,\n",
       " 'flag': 156,\n",
       " 'road': 157,\n",
       " 'person': 158,\n",
       " 'dressed': 159,\n",
       " 'coat': 160,\n",
       " 'busy': 161,\n",
       " 'sidewalk': 162,\n",
       " 'studying': 163,\n",
       " 'painting': 164,\n",
       " 'scene': 165,\n",
       " 'pants': 166,\n",
       " 'child': 167,\n",
       " 'climbs': 168,\n",
       " 'red': 169,\n",
       " 'ropes': 170,\n",
       " 'playground': 171,\n",
       " 'you': 172,\n",
       " 'know': 173,\n",
       " 'i': 174,\n",
       " 'am': 175,\n",
       " 'looking': 176,\n",
       " 'like': 177,\n",
       " 'justin': 178,\n",
       " 'bieber': 179,\n",
       " 'yellow': 180,\n",
       " 'jacket': 181,\n",
       " 'gazing': 182,\n",
       " 'something': 183,\n",
       " 'urinal': 184,\n",
       " 'coffee': 185,\n",
       " 'cup': 186,\n",
       " 'multicolored': 187,\n",
       " 'sky': 188,\n",
       " 'background': 189,\n",
       " 'old': 190,\n",
       " 'having': 191,\n",
       " 'beer': 192,\n",
       " 'alone': 193,\n",
       " 'trained': 194,\n",
       " 'police': 195,\n",
       " 'sits': 196,\n",
       " 'next': 197,\n",
       " 'handler': 198,\n",
       " 'van': 199,\n",
       " 'riding': 200,\n",
       " 'bike': 201,\n",
       " 'snowy': 202,\n",
       " 'uniformly': 203,\n",
       " 'shirts': 204,\n",
       " 'tie': 205,\n",
       " 'slacks': 206,\n",
       " 'converse': 207,\n",
       " 'an': 208,\n",
       " 'open': 209,\n",
       " 'backwards': 210,\n",
       " 'works': 211,\n",
       " 'machinery': 212,\n",
       " 'working': 213,\n",
       " 'factory': 214,\n",
       " 'setting': 215,\n",
       " 'packing': 216,\n",
       " 'jars': 217,\n",
       " 'candles': 218,\n",
       " 'boxes': 219,\n",
       " 'asian': 220,\n",
       " 'sweeping': 221,\n",
       " 'walkway': 222,\n",
       " 'leans': 223,\n",
       " 'car': 224,\n",
       " 'talk': 225,\n",
       " 'driver': 226,\n",
       " 'bicycle': 227,\n",
       " 'looks': 228,\n",
       " 'toddlers': 229,\n",
       " 'grass': 230,\n",
       " 'watching': 231,\n",
       " 'weird': 232,\n",
       " 'vehicle': 233,\n",
       " 'plaza': 234,\n",
       " 'walks': 235,\n",
       " 'silver': 236,\n",
       " 'beautiful': 237,\n",
       " 'bride': 238,\n",
       " 'new': 239,\n",
       " 'husband': 240,\n",
       " 'boy': 241,\n",
       " 'playing': 242,\n",
       " 'gamecube': 243,\n",
       " 'mcdonald': 244,\n",
       " \"'s\": 245,\n",
       " 'shakes': 246,\n",
       " 'edge': 247,\n",
       " 'beach': 248,\n",
       " 'ball': 249,\n",
       " 'group': 250,\n",
       " 'barbecue': 251,\n",
       " 'park': 252,\n",
       " 'sunglasses': 253,\n",
       " 'puts': 254,\n",
       " 'arm': 255,\n",
       " 'around': 256,\n",
       " 'blouse': 257,\n",
       " 'balloon': 258,\n",
       " 'eating': 259,\n",
       " 'outdoors': 260,\n",
       " 'picnic': 261,\n",
       " 'tables': 262,\n",
       " 'jump': 263,\n",
       " 'kicking': 264,\n",
       " 'over': 265,\n",
       " 'kids': 266,\n",
       " 'wood': 267,\n",
       " 'during': 268,\n",
       " 'tae': 269,\n",
       " 'kwon': 270,\n",
       " 'do': 271,\n",
       " 'competition': 272,\n",
       " 'pouring': 273,\n",
       " 'water': 274,\n",
       " 'shielding': 275,\n",
       " 'himself': 276,\n",
       " 'from': 277,\n",
       " 'sun': 278,\n",
       " 'trying': 279,\n",
       " 'piece': 280,\n",
       " 'paper': 281,\n",
       " 'overalls': 282,\n",
       " 'stone': 283,\n",
       " 'wall': 284,\n",
       " 'leaps': 285,\n",
       " 'log': 286,\n",
       " 'suit': 287,\n",
       " 'running': 288,\n",
       " 'past': 289,\n",
       " 'gentleman': 290,\n",
       " 'barefooted': 291,\n",
       " 'olive': 292,\n",
       " 'shorts': 293,\n",
       " 'grilling': 294,\n",
       " 'hotdogs': 295,\n",
       " 'propane': 296,\n",
       " 'grill': 297,\n",
       " 'holding': 298,\n",
       " 'plastic': 299,\n",
       " 'snow': 300,\n",
       " 'waiting': 301,\n",
       " 'for': 302,\n",
       " 'light': 303,\n",
       " 'skis': 304,\n",
       " 'artwork': 305,\n",
       " 'sale': 306,\n",
       " 'seven': 307,\n",
       " 'climbers': 308,\n",
       " 'ascending': 309,\n",
       " 'rock': 310,\n",
       " 'face': 311,\n",
       " 'whilst': 312,\n",
       " 'another': 313,\n",
       " 'stands': 314,\n",
       " 'rope': 315,\n",
       " 'gymnast': 316,\n",
       " 'supple': 317,\n",
       " 'body': 318,\n",
       " 'soars': 319,\n",
       " 'above': 320,\n",
       " 'balance': 321,\n",
       " 'beam': 322,\n",
       " 'pushing': 323,\n",
       " 'toy': 324,\n",
       " 'atv': 325,\n",
       " 'rubber': 326,\n",
       " 'pool': 327,\n",
       " 'windbreaker': 328,\n",
       " 'though': 329,\n",
       " 'rooftop': 330,\n",
       " 'binoculars': 331,\n",
       " 'below': 332,\n",
       " 'object': 333,\n",
       " 'that': 334,\n",
       " 'plane': 335,\n",
       " 'hose': 336,\n",
       " 'happily': 337,\n",
       " 'posing': 338,\n",
       " 'cart': 339,\n",
       " 'supermarket': 340,\n",
       " 'about': 341,\n",
       " 'catch': 342,\n",
       " 'guy': 343,\n",
       " 'hand': 344,\n",
       " 'covering': 345,\n",
       " 'part': 346,\n",
       " 'restaurant': 347,\n",
       " 'booth': 348,\n",
       " 'jumps': 349,\n",
       " 'up': 350,\n",
       " 'towards': 351,\n",
       " 'hikers': 352,\n",
       " 'resting': 353,\n",
       " 'patch': 354,\n",
       " 'showing': 355,\n",
       " 'creation': 356,\n",
       " 'father': 357,\n",
       " 'grown': 358,\n",
       " 'son': 359,\n",
       " 'camping': 360,\n",
       " 'trip': 361,\n",
       " 'wild': 362,\n",
       " 'bearded': 363,\n",
       " 'traveler': 364,\n",
       " 'reading': 365,\n",
       " 'map': 366,\n",
       " 'waves': 367,\n",
       " 'duck': 368,\n",
       " 'surrounded': 369,\n",
       " 'couple': 370,\n",
       " 'baby': 371,\n",
       " 'stroller': 372,\n",
       " 'some': 373,\n",
       " 'building': 374,\n",
       " 'parked': 375,\n",
       " 'runs': 376,\n",
       " 'through': 377,\n",
       " 'drilling': 378,\n",
       " 'frozen': 379,\n",
       " 'ice': 380,\n",
       " 'pond': 381,\n",
       " 'tan': 382,\n",
       " 'dogs': 383,\n",
       " 'along': 384,\n",
       " 'sandy': 385,\n",
       " 'picks': 386,\n",
       " 'path': 387,\n",
       " 'meadow': 388,\n",
       " 'attire': 389,\n",
       " 'shovels': 390,\n",
       " 'disregarding': 391,\n",
       " 'all': 392,\n",
       " 'public': 393,\n",
       " 'safety': 394,\n",
       " 'behind': 395,\n",
       " 'wedding': 396,\n",
       " 'wet': 397,\n",
       " 'carrying': 398,\n",
       " 'villagers': 399,\n",
       " 'selling': 400,\n",
       " 'crops': 401,\n",
       " 'market': 402,\n",
       " 'crowded': 403,\n",
       " 'concert': 404,\n",
       " 'approaching': 405,\n",
       " 'main': 406,\n",
       " 'singer': 407,\n",
       " 'who': 408,\n",
       " 'skateboard': 409,\n",
       " 'watches': 410,\n",
       " 'kayak': 411,\n",
       " 'them': 412,\n",
       " 'construction': 413,\n",
       " 'site': 414,\n",
       " 'billboard': 415,\n",
       " 'advertisement': 416,\n",
       " 'youths': 417,\n",
       " 'march': 418,\n",
       " 'waving': 419,\n",
       " 'flags': 420,\n",
       " 'color': 421,\n",
       " 'spectrum': 422,\n",
       " 'prepare': 423,\n",
       " 'fish': 424,\n",
       " 'tank': 425,\n",
       " 'flowing': 426,\n",
       " 'skirt': 427,\n",
       " 'stage': 428,\n",
       " 'singing': 429,\n",
       " 'song': 430,\n",
       " 'steps': 431,\n",
       " 'brown': 432,\n",
       " 'lab': 433,\n",
       " 'catching': 434,\n",
       " 'its': 435,\n",
       " 'mouth': 436,\n",
       " 'hockey': 437,\n",
       " 'goalie': 438,\n",
       " 'crouches': 439,\n",
       " 'goal': 440,\n",
       " 'stick': 441,\n",
       " 'backpack': 442,\n",
       " 'buildings': 443,\n",
       " 'courtyard': 444,\n",
       " 'art': 445,\n",
       " 'sculpture': 446,\n",
       " 'toddler': 447,\n",
       " 'railings': 448,\n",
       " 'grassy': 449,\n",
       " 'field': 450,\n",
       " 'kneels': 451,\n",
       " 'nearby': 452,\n",
       " 'skyscraper': 453,\n",
       " 'local': 454,\n",
       " 'fruit': 455,\n",
       " 'blond': 456,\n",
       " '-': 457,\n",
       " 'haired': 458,\n",
       " 'dark': 459,\n",
       " 'kid': 460,\n",
       " 'table': 461,\n",
       " 'eats': 462,\n",
       " 'electric': 463,\n",
       " 'softball': 464,\n",
       " 'hits': 465,\n",
       " 'almost': 466,\n",
       " 'directly': 467,\n",
       " 'downwards': 468,\n",
       " 'plays': 469,\n",
       " 'colored': 470,\n",
       " 'smoothing': 471,\n",
       " 'out': 472,\n",
       " 'concrete': 473,\n",
       " 'urban': 474,\n",
       " 'area': 475,\n",
       " 'nice': 476,\n",
       " 'blanket': 477,\n",
       " 'solitary': 478,\n",
       " 'bridge': 479,\n",
       " 'evening': 480,\n",
       " 'beans': 481,\n",
       " 'rest': 482,\n",
       " 'ledge': 483,\n",
       " 'moutains': 484,\n",
       " 'cross': 485,\n",
       " 'very': 486,\n",
       " 'tall': 487,\n",
       " 'footbridge': 488,\n",
       " 'tree': 489,\n",
       " 'covered': 490,\n",
       " 'hill': 491,\n",
       " 'overlooking': 492,\n",
       " 'inflatable': 493,\n",
       " 'boats': 494,\n",
       " 'have': 495,\n",
       " 'conversation': 496,\n",
       " 'hands': 497,\n",
       " 'older': 498,\n",
       " 'gray': 499,\n",
       " 'hair': 500,\n",
       " 'chair': 501,\n",
       " 'instrument': 502,\n",
       " 'made': 503,\n",
       " 'bamboo': 504,\n",
       " 'rides': 505,\n",
       " 'bricks': 506,\n",
       " '30': 507,\n",
       " 'somethings': 508,\n",
       " 'phone': 509,\n",
       " 'subway': 510,\n",
       " 'train': 511,\n",
       " 'crosswalk': 512,\n",
       " 'bus': 513,\n",
       " 'noddles': 514,\n",
       " 'bowl': 515,\n",
       " 'full': 516,\n",
       " 'head': 517,\n",
       " 'ocean': 518,\n",
       " 'side': 519,\n",
       " 'hole': 520,\n",
       " 'pose': 521,\n",
       " 'much': 522,\n",
       " 'too': 523,\n",
       " 'big': 524,\n",
       " 'individuals': 525,\n",
       " 'male': 526,\n",
       " 'female': 527,\n",
       " 'forested': 528,\n",
       " 'tub': 529,\n",
       " 'sleeping': 530,\n",
       " 'someone': 531,\n",
       " 'arms': 532,\n",
       " 'pink': 533,\n",
       " 'striped': 534,\n",
       " 'outfit': 535,\n",
       " 'member': 536,\n",
       " 'african': 537,\n",
       " 'tribe': 538,\n",
       " 'camera': 539,\n",
       " 'intently': 540,\n",
       " 'tribal': 541,\n",
       " 'dress': 542,\n",
       " 'samurai': 543,\n",
       " 'warrior': 544,\n",
       " 'takes': 545,\n",
       " 'sword': 546,\n",
       " 'sheath': 547,\n",
       " 'outdoor': 548,\n",
       " 'training': 549,\n",
       " 'mat': 550,\n",
       " 'rail': 551,\n",
       " 'facing': 552,\n",
       " 'others': 553,\n",
       " 'away': 554,\n",
       " 'it': 555,\n",
       " 'rocky': 556,\n",
       " 'riverbed': 557,\n",
       " 'security': 558,\n",
       " 'guard': 559,\n",
       " 'metal': 560,\n",
       " 'lighted': 561,\n",
       " 'purple': 562,\n",
       " 'washing': 563,\n",
       " 'crouch': 564,\n",
       " 'phones': 565,\n",
       " 'right': 566,\n",
       " 'bright': 567,\n",
       " 'house': 568,\n",
       " 'floor': 569,\n",
       " 'skateboarder': 570,\n",
       " 'doing': 571,\n",
       " 'trick': 572,\n",
       " 'board': 573,\n",
       " 'laughing': 574,\n",
       " 'bottle': 575,\n",
       " 'reaching': 576,\n",
       " 'shake': 577,\n",
       " 'communicating': 578,\n",
       " 'walkie': 579,\n",
       " 'talkie': 580,\n",
       " 'paddling': 581,\n",
       " 'river': 582,\n",
       " 'seen': 583,\n",
       " 'pigtails': 584,\n",
       " 'sweaters': 585,\n",
       " 'meal': 586,\n",
       " 'workers': 587,\n",
       " 'take': 588,\n",
       " 'seat': 589,\n",
       " 'steel': 590,\n",
       " 'mixing': 591,\n",
       " 'batter': 592,\n",
       " 'mud': 593,\n",
       " 'sunny': 594,\n",
       " 'day': 595,\n",
       " 'brochure': 596,\n",
       " 'jogging': 597,\n",
       " 'high': 598,\n",
       " 'dive': 599,\n",
       " 'lounges': 600,\n",
       " 'basin': 601,\n",
       " 'stop': 602,\n",
       " 'jeans': 603,\n",
       " 'asleep': 604,\n",
       " 'under': 605,\n",
       " 'home': 606,\n",
       " 'kitchen': 607,\n",
       " 'flipping': 608,\n",
       " 'pancake': 609,\n",
       " 'extremely': 610,\n",
       " 'firefighters': 611,\n",
       " 'responding': 612,\n",
       " 'alarm': 613,\n",
       " 'firetrucks': 614,\n",
       " 'shore': 615,\n",
       " 'vests': 616,\n",
       " 'magazine': 617,\n",
       " 'vendor': 618,\n",
       " 'colorful': 619,\n",
       " 'collage': 620,\n",
       " 'magazines': 621,\n",
       " 'jean': 622,\n",
       " 'bakery': 623,\n",
       " 'fat': 624,\n",
       " 'baker': 625,\n",
       " 'sleeps': 626,\n",
       " 'apprentice': 627,\n",
       " 'rubs': 628,\n",
       " 'flour': 629,\n",
       " 'eyes': 630,\n",
       " 'seated': 631,\n",
       " 'beside': 632,\n",
       " 'him': 633,\n",
       " 'shirtless': 634,\n",
       " 'shade': 635,\n",
       " 'tropical': 636,\n",
       " 'swim': 637,\n",
       " 'skier': 638,\n",
       " 'mountain': 639,\n",
       " 'mound': 640,\n",
       " 'dirt': 641,\n",
       " 'bikers': 642,\n",
       " 'race': 643,\n",
       " 'sharp': 644,\n",
       " 'left': 645,\n",
       " 'turn': 646,\n",
       " 'biking': 647,\n",
       " 'pile': 648,\n",
       " 'cane': 649,\n",
       " 'bends': 650,\n",
       " 'doctor': 651,\n",
       " 'nurses': 652,\n",
       " 'scrubs': 653,\n",
       " 'performing': 654,\n",
       " 'operation': 655,\n",
       " 'after': 656,\n",
       " 'woolly': 657,\n",
       " 'chases': 658,\n",
       " 'doberman': 659,\n",
       " 'there': 660,\n",
       " 'rolling': 661,\n",
       " 'bowling': 662,\n",
       " 'lane': 663,\n",
       " 'weathered': 664,\n",
       " 'donkey': 665,\n",
       " 'rocks': 666,\n",
       " 'napping': 667,\n",
       " 'couch': 668,\n",
       " 'throwing': 669,\n",
       " 'javelin': 670,\n",
       " 'track': 671,\n",
       " 'air': 672,\n",
       " 'balloons': 673,\n",
       " 'shoulder': 674,\n",
       " 'squat': 675,\n",
       " 'mall': 676,\n",
       " 'darkened': 677,\n",
       " 'room': 678,\n",
       " 'suds': 679,\n",
       " 'wiped': 680,\n",
       " 'clean': 681,\n",
       " 'dozens': 682,\n",
       " 'partying': 683,\n",
       " 'boat': 684,\n",
       " 'bikini': 685,\n",
       " 'kicks': 686,\n",
       " 'straw': 687,\n",
       " 'cowboy': 688,\n",
       " 'sliding': 689,\n",
       " 'slide': 690,\n",
       " 'tubes': 691,\n",
       " 'wetsuit': 692,\n",
       " 'ready': 693,\n",
       " 'truck': 694,\n",
       " 'country': 695,\n",
       " 'chefs': 696,\n",
       " 'burgers': 697,\n",
       " 'making': 698,\n",
       " 'silly': 699,\n",
       " 'faces': 700,\n",
       " 'fenced': 701,\n",
       " 'sparks': 702,\n",
       " 'flying': 703,\n",
       " 'work': 704,\n",
       " 'shoveling': 705,\n",
       " 'horses': 706,\n",
       " 'contained': 707,\n",
       " 'fire': 708,\n",
       " 'classic': 709,\n",
       " 'rustic': 710,\n",
       " 'volkswagen': 711,\n",
       " 'beetle': 712,\n",
       " 'assembles': 713,\n",
       " 'frame': 714,\n",
       " 'starring': 715,\n",
       " 'dock': 716,\n",
       " 'fixing': 717,\n",
       " 'equipment': 718,\n",
       " 'reddish': 719,\n",
       " 'applies': 720,\n",
       " 'mascara': 721,\n",
       " 'eyelashes': 722,\n",
       " 'ground': 723,\n",
       " 'indoor': 724,\n",
       " 'scooters': 725,\n",
       " 'regional': 726,\n",
       " 'helicopter': 727,\n",
       " 'land': 728,\n",
       " 'positions': 729,\n",
       " 'scaffolding': 730,\n",
       " 'fourteen': 731,\n",
       " 'assembled': 732,\n",
       " 'hall': 733,\n",
       " 'dining': 734,\n",
       " 'teenage': 735,\n",
       " 'family': 736,\n",
       " 'pan': 737,\n",
       " 'frying': 738,\n",
       " 'approached': 739,\n",
       " 'flamboyant': 740,\n",
       " 'feathered': 741,\n",
       " 'headress': 742,\n",
       " 'skiers': 743,\n",
       " 'way': 744,\n",
       " 'woodland': 745,\n",
       " 'skiiers': 746,\n",
       " 'stoop': 747,\n",
       " 'door': 748,\n",
       " 'she': 749,\n",
       " 'fills': 750,\n",
       " 'paperwork': 751,\n",
       " 'crossing': 752,\n",
       " 'intersection': 753,\n",
       " 'corsage': 754,\n",
       " 'clasps': 755,\n",
       " 'lap': 756,\n",
       " 'mother': 757,\n",
       " 'fishing': 758,\n",
       " 'boardwalk': 759,\n",
       " 'six': 760,\n",
       " 'game': 761,\n",
       " 'paddles': 762,\n",
       " 'engine': 763,\n",
       " 'antique': 764,\n",
       " 'automobile': 765,\n",
       " 'gas': 766,\n",
       " 'canister': 767,\n",
       " 'pony': 768,\n",
       " 'pull': 769,\n",
       " 'carriage': 770,\n",
       " 'driven': 771,\n",
       " 'sheer': 772,\n",
       " 'cliff': 773,\n",
       " 'using': 774,\n",
       " 'chalk': 775,\n",
       " 'drawing': 776,\n",
       " 'adults': 777,\n",
       " 'pretending': 778,\n",
       " 'kick': 779,\n",
       " 'he': 780,\n",
       " 'midsentence': 781,\n",
       " 'swimming': 782,\n",
       " 'trunks': 783,\n",
       " 'platform': 784,\n",
       " 'meticulously': 785,\n",
       " 'sewing': 786,\n",
       " 'machine': 787,\n",
       " 't': 788,\n",
       " 'toward': 789,\n",
       " 'raised': 790,\n",
       " 'farm': 791,\n",
       " 'peppers': 792,\n",
       " 'blown': 793,\n",
       " 'bubbles': 794,\n",
       " 'lawn': 795,\n",
       " 'tunnel': 796,\n",
       " 'obstacle': 797,\n",
       " 'course': 798,\n",
       " 'barbecuing': 799,\n",
       " 'flower': 800,\n",
       " 'print': 801,\n",
       " 'bathing': 802,\n",
       " 'swimsuit': 803,\n",
       " 'handrail': 804,\n",
       " 'railing': 805,\n",
       " 'row': 806,\n",
       " 'smiles': 807,\n",
       " 'underwater': 808,\n",
       " 'discussion': 809,\n",
       " 'taking': 810,\n",
       " 'break': 811,\n",
       " 'snowmobiling': 812,\n",
       " 'ride': 813,\n",
       " 'removing': 814,\n",
       " 'roof': 815,\n",
       " 'folding': 816,\n",
       " 'stack': 817,\n",
       " 'dusk': 818,\n",
       " 'blowing': 819,\n",
       " 'petals': 820,\n",
       " 'wheeler': 821,\n",
       " 'cast': 822,\n",
       " 'iron': 823,\n",
       " 'spatula': 824,\n",
       " 'hugging': 825,\n",
       " 'cow': 826,\n",
       " 'ship': 827,\n",
       " 'awaiting': 828,\n",
       " 'arrival': 829,\n",
       " 'sandals': 830,\n",
       " 'cardigan': 831,\n",
       " 'microphone': 832,\n",
       " 'elephant': 833,\n",
       " 'structures': 834,\n",
       " 'trees': 835,\n",
       " 'mexican': 836,\n",
       " 'hood': 837,\n",
       " 'gather': 838,\n",
       " 'different': 839,\n",
       " 'types': 840,\n",
       " 'crying': 841,\n",
       " 'tipped': 842,\n",
       " 'carries': 843,\n",
       " 'soccer': 844,\n",
       " 'scooping': 845,\n",
       " 'cream': 846,\n",
       " 'freezer': 847,\n",
       " 'stools': 848,\n",
       " 'american': 849,\n",
       " 'spread': 850,\n",
       " 'wrong': 851,\n",
       " 'direction': 852,\n",
       " 'picture': 853,\n",
       " 'cyclist': 854,\n",
       " 'curved': 855,\n",
       " 'denim': 856,\n",
       " 'thumb': 857,\n",
       " 'kissing': 858,\n",
       " 'going': 859,\n",
       " 'escalator': 860,\n",
       " 'player': 861,\n",
       " 'being': 862,\n",
       " 'held': 863,\n",
       " 'teammates': 864,\n",
       " 'opposing': 865,\n",
       " 'reaches': 866,\n",
       " 'constructing': 867,\n",
       " 'desert': 868,\n",
       " 'friends': 869,\n",
       " 'adorned': 870,\n",
       " 'paint': 871,\n",
       " 'headbands': 872,\n",
       " 'sling': 873,\n",
       " 'bag': 874,\n",
       " 'fashioned': 875,\n",
       " 'video': 876,\n",
       " 'odd': 877,\n",
       " 'clothes': 878,\n",
       " 'porch': 879,\n",
       " 'funky': 880,\n",
       " 'prevent': 881,\n",
       " 'team': 882,\n",
       " 'adult': 883,\n",
       " 'walk': 884,\n",
       " 'apron': 885,\n",
       " 'curb': 886,\n",
       " 'frisbee': 887,\n",
       " 'audience': 888,\n",
       " 'tennis': 889,\n",
       " 'players': 890,\n",
       " 'courts': 891,\n",
       " 'jugglers': 892,\n",
       " 'flaming': 893,\n",
       " 'torches': 894,\n",
       " 'no': 895,\n",
       " 'shoes': 896,\n",
       " 'smooth': 897,\n",
       " 'gap': 898,\n",
       " 'hanging': 899,\n",
       " 'speedo': 900,\n",
       " 'goggles': 901,\n",
       " 'breath': 902,\n",
       " 'motor': 903,\n",
       " 'scooter': 904,\n",
       " 'ladies': 905,\n",
       " 'card': 906,\n",
       " 'drinking': 907,\n",
       " 'enjoy': 908,\n",
       " 'gathering': 909,\n",
       " 'pabst': 910,\n",
       " 'ribbon': 911,\n",
       " 'diet': 912,\n",
       " 'coke': 913,\n",
       " 'climber': 914,\n",
       " 'frog': 915,\n",
       " 'short': 916,\n",
       " 'bird': 917,\n",
       " 'sunflower': 918,\n",
       " 'seeds': 919,\n",
       " 'hit': 920,\n",
       " 'this': 921,\n",
       " 'device': 922,\n",
       " 'camper': 923,\n",
       " 'vehicles': 924,\n",
       " 'surf': 925,\n",
       " 'muslim': 926,\n",
       " 'across': 927,\n",
       " 'elevated': 928,\n",
       " 'torwards': 929,\n",
       " 'maintenance': 930,\n",
       " 'handstand': 931,\n",
       " 'bed': 932,\n",
       " 'repairs': 933,\n",
       " 'kneeling': 934,\n",
       " 'workman': 935,\n",
       " 'completing': 936,\n",
       " 'snowboard': 937,\n",
       " 'atop': 938,\n",
       " 'golf': 939,\n",
       " 'watch': 940,\n",
       " 'karate': 941,\n",
       " 'trophy': 942,\n",
       " 'floaters': 943,\n",
       " 'lake': 944,\n",
       " 'cuts': 945,\n",
       " 'hamburger': 946,\n",
       " 'dirty': 947,\n",
       " 'knee': 948,\n",
       " 'nude': 949,\n",
       " 'statue': 950,\n",
       " 'helps': 951,\n",
       " 'wave': 952,\n",
       " 'counter': 953,\n",
       " 'jewelery': 954,\n",
       " 'store': 955,\n",
       " 'church': 956,\n",
       " 'number': 957,\n",
       " 'themselves': 958,\n",
       " 'coast': 959,\n",
       " 'carpentry': 960,\n",
       " 'project': 961,\n",
       " 'tools': 962,\n",
       " 'briefcase': 963,\n",
       " 'hurrying': 964,\n",
       " 'somewhere': 965,\n",
       " 'brunette': 966,\n",
       " 'bald': 967,\n",
       " 'chicken': 968,\n",
       " 'run': 969,\n",
       " 'mouths': 970,\n",
       " 'strolls': 971,\n",
       " 'scarf': 972,\n",
       " 'knit': 973,\n",
       " 'seaweed': 974,\n",
       " 'snows': 975,\n",
       " 'jigsaw': 976,\n",
       " 'cutting': 977,\n",
       " 'roller': 978,\n",
       " 'derby': 979,\n",
       " 'beds': 980,\n",
       " 'huge': 981,\n",
       " 'chainsaw': 982,\n",
       " 'motorcycle': 983,\n",
       " 'without': 984,\n",
       " 'enter': 985,\n",
       " 'handwritten': 986,\n",
       " 'sign': 987,\n",
       " 'says': 988,\n",
       " '\"': 989,\n",
       " 'welcome': 990,\n",
       " 'putting': 991,\n",
       " 'line': 992,\n",
       " 'slopes': 993,\n",
       " 'strolling': 994,\n",
       " 'decorations': 995,\n",
       " 'ceiling': 996,\n",
       " 'blacksmith': 997,\n",
       " 'shoeing': 998,\n",
       " 'horse': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG_VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60b836af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers work parallelly. Transformers do not understand the order of words (unlike RNNs).\n",
    "# So to let transformers know about the position of each word, we manually add information about word positions using a mathematical formula.\n",
    "\n",
    "# creating class \"PositionalEncoding\" that inharits the PyTorch base NN\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000): # create contructor that accepts the embedding dimension (d_model) and max seq len, here it is by default 1000\n",
    "        super().__init__() # initialize the parent class\n",
    "        pe = torch.zeros(max_len, d_model) #Create empty matrix with size(max_len, d_model), this will store the positional encoding:[1000,512]\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # Create the position tensor and add one dim at 1 shape will be [max_len, 1]\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # divide term x^y = e^(ylog(x))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # PE for even term\n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # PE for odd term\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1) # Add one more dim at 0 and change 0->1 [max_len, d_model] -> [1, max_len, d_model]--> [mx_len, 1, d_model]\n",
    "        ## register_buffer is used to save the tensor as part of the model's state_dict, but not as a model parameter.\n",
    "        # so it will not be the part of training\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8376894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multihead Attention which inharits PyTorch's base NN\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    # initialize the constructor of multi-head attention module that has attributes d_model, and num_heads\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        self.d_model = d_model # embedding dimension, in original paper 512\n",
    "        self.num_heads = num_heads # number of attention heads, in original paper 8\n",
    "        self.d_k = d_model // num_heads # Dimension of each head , as per original paper 512/8=64\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model) # linear layer for query - Q matrix of size (d_model,d_model) - (512,512)\n",
    "        self.W_k = nn.Linear(d_model, d_model) # linear layer for query - K matrix of size (d_model,d_model) - (512,512)\n",
    "        self.W_v = nn.Linear(d_model, d_model) # linear layer for query - V matrix of size (d_model,d_model) - (512,512)\n",
    "        self.W_o = nn.Linear(d_model, d_model) # linear layer for query - V matrix of size (d_model,d_model) - (512,512)\n",
    "\n",
    "    # Calculates the self attention\n",
    "    # Instead of creating 8 small layers of size 64, I create one big layer of size 512 (d_model).\n",
    "    # I will logically split the output of this layer later in the forward method.\n",
    "    # This is computationally more efficient.\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "\n",
    "        # apply mask if provided\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9) # mask out the positions with -inf\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1) # softmax to get attention probabilities\n",
    "        output = torch.matmul(attn_probs, V) # weighted sum of values\n",
    "        return output # output of attention mechanism\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        batch_size = Q.size(0) # get batch size\n",
    "\n",
    "        # linear transformation and reshape for multi-head attention\n",
    "        # W_q is applied to the entire d_model dimension, then reshaped to (batch_size, seq_len, num_heads, d_k)\n",
    "        # Here, -1 infers the sequence length dimension automatically\n",
    "        # Here, batch_size = Q.size(0)\n",
    "        # here, d_k = d_model / num_heads\n",
    "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "\n",
    "        # Note: [batch_size, seq_len, d_model] --> [batch_size, seq_len, num_heads, head_dim]\n",
    "        # and [batch_size, seq_len, num_heads, head_dim]--> [batch_size, num_heads, seq_len, head_dim]\n",
    "\n",
    "        # Inputs: Q, K, V are tensors reshaped for multi-head processing.\n",
    "        # [batch_size, seq_len, num_heads, head_dim] -->  [batch_size, num_heads, seq_len, head_dim]\n",
    "        # Their shape is usually [Batch, Seq_Len, Head, Head_Dim]\n",
    "        output = self.scaled_dot_product_attention(Q, K, V, mask)# apply scaled dot-product attention\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model) # reshape back to original shape\n",
    "        return self.W_o(output) # final linear transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16646ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position-wise Feed Forward Network\n",
    "class PositionwiseFeedforward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):      # intialize the constructor with attribut d_model and no of nodes in hidden layer\n",
    "        super().__init__()                  # call parent class\n",
    "        self.fc1 = nn.Linear(d_model, d_ff) # first linear layer\n",
    "        self.fc2 = nn.Linear(d_ff, d_model) # second linear layer\n",
    "        self.relu = nn.ReLU()               # activation function - ReLU\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7199f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Section\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionwiseFeedforward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)   # Self attention calculation with MHA\n",
    "        x = self.norm1(x + self.dropout(attn_output)) # Add and Norm\n",
    "        ff_output = self.feed_forward(x)              # Feed forward Neural Network\n",
    "        x = self.norm2(x + self.dropout(ff_output))   # Add and Norm\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "000995ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Section\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionwiseFeedforward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask, trg_mask):\n",
    "        attn_output = self.self_attn(x, x, x, trg_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5fecb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Class\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, trg_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model) # source embedding for src language - german\n",
    "        self.decoder_embedding = nn.Embedding(trg_vocab_size, d_model) # trg embedding for trg language - english\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length) #creating PE object\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc_out = nn.Linear(d_model, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([d_model]))\n",
    "\n",
    "    def generate_mask(self, src, trg):\n",
    "        src_mask = (src != SRC_VOCAB[PAD_TOKEN]).unsqueeze(1).unsqueeze(2)\n",
    "        trg_mask = (trg != TRG_VOCAB[PAD_TOKEN]).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = trg.shape[1]\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        trg_mask = trg_mask & nopeak_mask\n",
    "        return src_mask, trg_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask, trg_mask = self.generate_mask(src, trg)\n",
    "\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src) * self.scale))\n",
    "        trg_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(trg) * self.scale))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = trg_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, trg_mask)\n",
    "\n",
    "        output = self.fc_out(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e705ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters from Paper \"Attention is All you need\"\n",
    "\n",
    "SRC_VOCAB_SIZE = len(SRC_VOCAB)\n",
    "TRG_VOCAB_SIZE = len(TRG_VOCAB)\n",
    "D_MODEL = 512\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 6\n",
    "D_FF = 2048\n",
    "MAX_SEQ_LENGTH = 100\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c6137cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Transformer(SRC_VOCAB_SIZE, TRG_VOCAB_SIZE, D_MODEL, NUM_HEADS, NUM_LAYERS, D_FF, MAX_SEQ_LENGTH, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95c541a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 63,738,949 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f\"The model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc833669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "PAD_IDX = SRC_VOCAB[PAD_TOKEN]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "571300c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function for DataLoader\n",
    "def collate_fn(batch):\n",
    "\n",
    "    src_batch, trg_batch = [], []\n",
    "\n",
    "    for sample in batch:\n",
    "        src_batch.append(torch.tensor([SRC_VOCAB.get(token, SRC_VOCAB[UNK_TOKEN]) for token in [SOS_TOKEN] + sample['src'] + [EOS_TOKEN]]))\n",
    "        trg_batch.append(torch.tensor([TRG_VOCAB.get(token, TRG_VOCAB[UNK_TOKEN]) for token in [SOS_TOKEN] + sample['trg'] + [EOS_TOKEN]]))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=SRC_VOCAB[PAD_TOKEN])\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=TRG_VOCAB[PAD_TOKEN])\n",
    "\n",
    "    return src_batch.transpose(0, 1), trg_batch.transpose(0, 1)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train() # Sets the model to the tainning mode\n",
    "    epoch_loss = 0 # initialize the running loss\n",
    "    print(len(iterator))\n",
    "    for src, trg in tqdm(iterator, desc=\"Training\", leave=False): #Training Loop Over the Data Loader, for each iter a batch of src,trg and tqdm give progress bar\n",
    "        optimizer.zero_grad() #Reset gradients\n",
    "\n",
    "        output = model(src, trg[:, :-1]) #during training we use teacher forcing means inpur: <sos> i like coffee; outpu: <sos> i like coffee <eos>. means i want transformer to predict <eos>\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src, trg = batch\n",
    "\n",
    "            output = model(src, trg[:, :-1])\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def translate_sentence(sentence, src_vocab, trg_vocab, model, device, max_len=50):\n",
    "    model.eval()\n",
    "\n",
    "    tokens = [SOS_TOKEN] + tokenize_de(sentence) + [EOS_TOKEN]\n",
    "\n",
    "    src_indexes = [src_vocab.get(token, src_vocab[UNK_TOKEN]) for token in tokens]\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    src_mask = model.generate_mask(src_tensor, src_tensor)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder_embedding(src_tensor)\n",
    "        for enc_layer in model.encoder_layers:\n",
    "            enc_src = enc_layer(enc_src, src_mask[0])\n",
    "\n",
    "    trg_indexes = [trg_vocab[SOS_TOKEN]]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "        trg_mask = model.generate_mask(src_tensor, trg_tensor)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.decoder_embedding(trg_tensor)\n",
    "            for dec_layer in model.decoder_layers:\n",
    "                output = dec_layer(output, enc_src, src_mask[0], trg_mask[1])\n",
    "            output = model.fc_out(output)\n",
    "\n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_vocab[EOS_TOKEN]:\n",
    "            break\n",
    "\n",
    "    trg_tokens = [list(trg_vocab.keys())[list(trg_vocab.values()).index(i)] for i in trg_indexes]\n",
    "\n",
    "    return trg_tokens[1:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f167445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 23.0m 10.955479383468628s\n",
      "\tTrain Loss: 3.767 | Train PPL:  43.238\n",
      "\t Val. Loss: 3.019 |  Val. PPL:  20.481\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 21.0m 53.172733306884766s\n",
      "\tTrain Loss: 2.786 | Train PPL:  16.215\n",
      "\t Val. Loss: 2.622 |  Val. PPL:  13.759\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 20.0m 51.00803804397583s\n",
      "\tTrain Loss: 2.396 | Train PPL:  10.975\n",
      "\t Val. Loss: 2.395 |  Val. PPL:  10.972\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 20.0m 52.148905992507935s\n",
      "\tTrain Loss: 2.123 | Train PPL:   8.355\n",
      "\t Val. Loss: 2.251 |  Val. PPL:   9.499\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 20.0m 50.884140729904175s\n",
      "\tTrain Loss: 1.899 | Train PPL:   6.678\n",
      "\t Val. Loss: 2.204 |  Val. PPL:   9.064\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 20.0m 45.63326358795166s\n",
      "\tTrain Loss: 1.708 | Train PPL:   5.519\n",
      "\t Val. Loss: 2.124 |  Val. PPL:   8.364\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 20.0m 47.67880916595459s\n",
      "\tTrain Loss: 1.533 | Train PPL:   4.632\n",
      "\t Val. Loss: 2.119 |  Val. PPL:   8.322\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 20.0m 52.00290060043335s\n",
      "\tTrain Loss: 1.373 | Train PPL:   3.948\n",
      "\t Val. Loss: 2.106 |  Val. PPL:   8.216\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 20.0m 51.1942675113678s\n",
      "\tTrain Loss: 1.220 | Train PPL:   3.388\n",
      "\t Val. Loss: 2.146 |  Val. PPL:   8.550\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 20.0m 51.257466316223145s\n",
      "\tTrain Loss: 1.080 | Train PPL:   2.945\n",
      "\t Val. Loss: 2.169 |  Val. PPL:   8.753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training loop\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1.0\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, val_dataloader, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'transformer-translation-model.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "\n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load('transformer-translation-model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e626ba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: ein mann mit einem orangefarbenen hut , der etwas anstarrt .\n",
      "Target: a man in an orange hat starring at something .\n",
      "Predicted: a man in an orange hat taking something with something .\n",
      "\n",
      "Source: ein boston terrier läuft über saftig-grünes gras vor einem weißen zaun .\n",
      "Target: a boston terrier is running on lush green grass in front of a white fence .\n",
      "Predicted: a lone rock climber runs over a white fence in front of a white fence .\n",
      "\n",
      "Source: ein mädchen in einem karateanzug bricht ein brett mit einem tritt .\n",
      "Target: a girl in karate uniform breaking a stick with a front kick .\n",
      "Predicted: a girl in a karate uniform kicks a board in a board .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example translations\n",
    "for example_idx in range(3):  # Change the range to translate more examples\n",
    "    src = test_data[example_idx]['src']\n",
    "    trg = test_data[example_idx]['trg']\n",
    "\n",
    "    print(f'Source: {\" \".join(src)}')\n",
    "    print(f'Target: {\" \".join(trg)}')\n",
    "\n",
    "    translation = translate_sentence(\" \".join(src), SRC_VOCAB, TRG_VOCAB, model, torch.device('cpu' if torch.cuda.is_available() else 'cpu'))\n",
    "    print(f'Predicted: {\" \".join(translation)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12e2ada9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'final_transformer_translation_model.pt'\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'final_transformer_translation_model.pt')\n",
    "print(\"Model saved as 'final_transformer_translation_model.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2be7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d8a166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c9b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6068412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8478b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d145b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dfcc69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798017c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2321e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7513882c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abf3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76bf563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c048f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ce0723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d6edb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e1682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d41a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3bdcac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32313464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e77924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2df64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6d8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec474c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4da73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf49aa18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9349809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
